# predictN2O: Machine Learning for Nitrous Oxide Emission Forecasting

Nitrous oxide (Nâ‚‚O) is a potent greenhouse gas, and wastewater treatment plants are significant sources due to biological processes during water purification. This repository provides an open-source, modular pipeline to forecast Nâ‚‚O emissions from real process data using state-of-the-art machine learning.

predictN2O combines robust data preparation, feature engineering, model training, and evaluation to deliver reproducible results and enable research in environmental data science.



## Master's Thesis

This repository is the **technical appendix** to the Master's Thesis:

**"Data-Driven Forecasting of Nitrous Oxide Emissions at a Wastewater Treatment Plant"**  
by **Ali Ãœnal**, submitted to TH KÃ¶ln, 2025.

The thesis provides full scientific context, methodology, and interpretation of results.  


## Table of Contents

- [Project Overview](#project-overview)
- [Background & Motivation](#background--motivation)
- [Repository Structure](#repository-structure)
- [Setup & Installation](#setup--installation)
- [Usage Example](#usage-example)
- [The Jupyter Notebooks](#the-jupyter-notebooks)
- [Reproducibility Notes](#reproducibility-notes)
- [License](#license)
- [Contributing & Issues](#contributing--issues)



## Project Overview

predictN2O is a modular Python pipeline for supervised machine learning (Random Forest, XGBoost, KNN) to forecast Nâ‚‚O emissions from wastewater treatment data.  
All preprocessing, feature engineering, and evaluation steps are transparent and reproducible.



## Background & Motivation

Wastewater treatment plants release Nâ‚‚O, a greenhouse gas with a global warming potential over 270 times higher than COâ‚‚.  
Traditional (mechanistic) models struggle to predict dynamic, short-term emission peaks due to the complex, nonlinear nature of the underlying biological processes.  
Machine learning (ML) and deep learning (DL) approaches can process large, real-world datasets and discover hidden patterns, improving the prediction and management of Nâ‚‚O emissions.  
This project demonstrates how ML/DL models can act as "soft sensors" for real-time environmental monitoring and decision support in wastewater management.

## Data Source

The dataset used in this project is a publicly available dataset from the **Altenrhein Wastewater Treatment Plant (WWTP)** in Switzerland, provided by **ARA Altenrhein AG**.

ðŸ”— DOI of the full dataset: [https://doi.org/10.25678/0003H2](https://doi.org/10.25678/0003H2)

For the analyses conducted in this project, a subset of the dataset was used, covering the **calendar year 2016**.  
This specific subset has also been used in this study:

> Huang, Z., Bai, Y., & Liu, H. (2025). *Symmetry-Inspired Prediction of Nitrous Oxide Emissions in Wastewater Treatment Using Deep Learning and Explainable Analysis*. 
> ðŸ”— [https://doi.org/10.3390/sym17020297](https://doi.org/10.3390/sym17020297)

**Data characteristics:**
- Source: ARA Altenrhein AG (via public release)
- Temporal resolution: 15-minute intervals
- Variables: Nâ‚‚O , dissolved oxygen (DO), temperature, flow
- Time frame: January 1 to December 31, 2016

The file `AltenrheinWWTP.csv` included in this repository corresponds to this filtered 2016 subset and is used solely for academic and non-commercial purposes.


## Repository Structure

The project is structured modularly to ensure high maintainability and reproducibility.

```text
predictN2O/
â”‚
â”œâ”€â”€ data/                   # Contains original and preprocessed data for Altenrhein WWTP.
â”‚   
â”‚
â”œâ”€â”€ notebooks/              # Notebooks for data analysis (EDA), model prototyping (Prophet), and final result visualization.
â”‚
â”œâ”€â”€ results/                # All generated outputs (models, figures, logs).
â”‚   â”œâ”€â”€ model_outputs/      # Saved trained models (.pkl).
â”‚   â”œâ”€â”€ figures/            # Plots generated by 03_Results_Visualization.ipynb and SHAP & Feature Importance Analysis.
â”‚   â””â”€â”€ logs/               # Log files from pipeline runs.
â”‚
â”œâ”€â”€ src/                    # All Python source code for the pipeline.
â”‚   â”œâ”€â”€ main.py             # Main script to run the training and evaluation pipeline.
â”‚   â”œâ”€â”€ config.py           # Central configuration file (paths, periods, etc.).
â”‚   â”œâ”€â”€ data_loader.py      # Loads and cleans the raw data.
â”‚   â”œâ”€â”€ feature_engineering.py # Creates new features (lags, rolling features).
â”‚   â”œâ”€â”€ models.py           # Defines and trains the machine learning models.
â”‚   â”œâ”€â”€ evaluation.py       # Calculates and displays model performance metrics.
â”‚   â”œâ”€â”€ augmentation.py     # Augments the training dataset by adding artificial noise.
â”‚   â”œâ”€â”€ param_grids.py      # Contains hyperparameter grids for model tuning.
â”‚   â”œâ”€â”€ resampling.py       # Defines resampling rules for each model.
â”‚   â””â”€â”€ ...                 # Other utility modules.
â”‚
â”œâ”€â”€ .gitignore              # Specifies files for Git to ignore (e.g., raw data files).
â”œâ”€â”€ LICENSE                 # Project license (CC BY-NC-SA 4.0).
â”œâ”€â”€ requirements.txt        # A list of all required Python packages.
â””â”€â”€ README.md               # Project overview and usage instructions.
```


## Setup & Installation

> This project requires Python â‰¥ 3.8 and TensorFlow (for DNN support).  
> It is strongly recommended to use a virtual environment.

1. **Clone the repository**  
   ```sh
   cd predictN2O
   ```

2. **Install dependencies**
   ```sh
   pip install -r requirements.txt
   ```



## Usage Example

Run the training and evaluation pipeline with default parameters:

```sh
python -m src.main
```

### Parameterization

You can override default parameters via command-line arguments. For example:

```sh
python -m src.main --model XGBoost --split 0.7 --augment 3 --noise 0.01
```
- `--model` Model type (XGBoost, RandomForest, KNN)
- `--split` Train/test split ratio (e.g. 0.8)
- `--augment` Number of data augmentation rounds
- `--noise` Noise level for augmentation

All outputs (trained models, results, and plots) are stored in the `/results/` directory.



## The Jupyter Notebooks

The `/notebooks` directory contains the project's exploratory work, documenting the journey from raw data to the final pipeline. They provide deeper insights into the data and the modeling decisions.

-   **`01_EDA.ipynb` â€” Exploratory Data Analysis:** This notebook covers the initial investigation of the data. It includes visualizing the time series, analyzing correlations between features, and examining data distributions.

-   **`02_Prophet_Training.ipynb` â€” Prophet Model Prototyping:** As the Prophet model has a distinct API from the scikit-learn models, its training and evaluation are demonstrated here. It serves as an important baseline and alternative modeling approach.

-   **`03_Results_Visualization.ipynb` â€” Final Results Visualization:** This notebook loads the predictions saved by the main pipeline and creates comprehensive, often interactive plots to visually compare the performance of different models.





## Reproducibility Notes

- All random seeds are fixed (`RANDOM_SEED = 42`)
- Results may vary slightly
- If problems occur with imports: check that the correct Python interpreter is active



## License

This project is licensed under the **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)**.  
See the [LICENSE](LICENSE) file for full details.



## Contributing & Issues

Contributions, bug reports, and feedback are welcome!  
Please open an [issue](https://github.com/ali-unal/PredictN2O/issue) or submit a pull request.

---

**Contact:**  
Ali Ãœnal â€” ali@unal.de

