{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fa2755-671a-44cf-b759-7f3fbf97cb7d",
   "metadata": {},
   "source": [
    "## Visualization of Results of a Model\n",
    "\n",
    "This notebook visualizes the performance of different machine learning models based on their predictions and evaluation metrics.\n",
    "\n",
    "The visualizations include:\n",
    "- **True vs. Predicted scatter plots** to assess how closely predictions align with actual values.\n",
    "- **Time series plots** showing the evolution of true and predicted values over time.\n",
    "- **Residual analysis** via histograms and residual vs. predicted scatter plots to evaluate model errors.\n",
    "- **Bar plots of performance metrics** (R², RMSE, MAE) across regions and datasets (train/test) for comparison.\n",
    "\n",
    "These plots are generated automatically for each model and time period from pre-saved CSV files containing prediction results and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4a6f19-81d1-40d6-b2f4-7c89904d4704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de88a3f7-22f1-4b9c-aab4-a249faa0d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plots for KNN, Januar–März saved.\n",
      "Plots for KNN, Mai–Oktober saved.\n",
      "Plots for KNN, März–Mitte Mai saved.\n",
      "Model comparison for KNN, R2 saved to ../results/figures/KNN\\model_comparison_r2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alisa\\AppData\\Local\\Temp\\ipykernel_25296\\2281883044.py:157: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(\n",
      "C:\\Users\\alisa\\AppData\\Local\\Temp\\ipykernel_25296\\2281883044.py:157: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model comparison for KNN, RMSE saved to ../results/figures/KNN\\model_comparison_rmse.png\n",
      "Model comparison for KNN, MAE saved to ../results/figures/KNN\\model_comparison_mae.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alisa\\AppData\\Local\\Temp\\ipykernel_25296\\2281883044.py:157: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    }
   ],
   "source": [
    "def safe_str(s):\n",
    "    \"\"\"Creates a safe string for filenames and directory names.\n",
    "\n",
    "    Args:\n",
    "        s: The input string or NaN.\n",
    "\n",
    "    Returns:\n",
    "        A sanitized string safe for use in file or directory names.\n",
    "    \"\"\"\n",
    "    if pd.isnull(s):\n",
    "        return \"unknown\"\n",
    "    s = str(s)\n",
    "    return (s.replace(' ', '_')\n",
    "              .replace('–', '-')\n",
    "              .replace('ä', 'ae')\n",
    "              .replace('ö', 'oe')\n",
    "              .replace('ü', 'ue')\n",
    "              .replace('ß', 'ss'))\n",
    "\n",
    "# Configuration\n",
    "PREDICTION_DIR = \"../results/predictions/\"\n",
    "BASE_OUTPUT_DIR = \"../results/figures/\"\n",
    "METRIC_FILE = \"../results/model_comparison.csv\"\n",
    "os.makedirs(BASE_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load prediction CSV files\n",
    "csv_files = glob.glob(os.path.join(PREDICTION_DIR, \"*.csv\"))\n",
    "df = pd.concat([pd.read_csv(f) for f in csv_files], ignore_index=True)\n",
    "df[\"model\"] = df[\"model\"].astype(str)\n",
    "df[\"periode\"] = df[\"periode\"].astype(str)\n",
    "\n",
    "def plot_true_vs_pred(df, path):\n",
    "    \"\"\"Scatter plot of true values vs. predicted values.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing 'true' and 'prediction' columns.\n",
    "        path: File path to save the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.scatterplot(x='true', y='prediction', data=df, alpha=0.5)\n",
    "    minval = min(df['true'].min(), df['prediction'].min())\n",
    "    maxval = max(df['true'].max(), df['prediction'].max())\n",
    "    plt.plot([minval, maxval], [minval, maxval], 'r--', label=\"Ideal\")\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Prediction\")\n",
    "    plt.title(\"True vs. Prediction\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_true_pred_over_time(df, path):\n",
    "    \"\"\"Time series plot comparing true and predicted values.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'time', 'true', and 'prediction' columns.\n",
    "        path: File path to save the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(pd.to_datetime(df['time']), df['true'], label='True', linewidth=2)\n",
    "    plt.plot(pd.to_datetime(df['time']),\n",
    "             df['prediction'],\n",
    "             label='Prediction',\n",
    "             linestyle='--',\n",
    "             linewidth=2)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"N₂O\")\n",
    "    plt.title(\"Time Series: True vs. Prediction\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_residual_hist(df, path):\n",
    "    \"\"\"Histogram of residuals (true - prediction).\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'true' and 'prediction' columns.\n",
    "        path: File path to save the plot.\n",
    "    \"\"\"\n",
    "    residuals = df['true'] - df['prediction']\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(residuals, kde=True, bins=30, color='purple')\n",
    "    plt.xlabel(\"Residual (True - Prediction)\")\n",
    "    plt.title(\"Histogram of Residuals\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "def plot_residual_vs_pred(df, path):\n",
    "    \"\"\"Plot residuals against predicted values.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with 'true' and 'prediction' columns.\n",
    "        path: File path to save the plot.\n",
    "    \"\"\"\n",
    "    residuals = df['true'] - df['prediction']\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.scatterplot(x=df['prediction'], y=residuals, alpha=0.5)\n",
    "    plt.axhline(0, color='r', linestyle='--')\n",
    "    plt.xlabel(\"Prediction\")\n",
    "    plt.ylabel(\"Residual (True - Prediction)\")\n",
    "    plt.title(\"Residuals vs. Prediction\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "# Generate plots for each model and period\n",
    "for model in sorted(df[\"model\"].unique()):\n",
    "    model_safe = safe_str(model)\n",
    "    model_output_dir = os.path.join(BASE_OUTPUT_DIR, model_safe)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "    for period in sorted(df[\"periode\"].unique()):\n",
    "        df_sel = df[(df[\"model\"] == model) & (df[\"periode\"] == period)]\n",
    "        if df_sel.empty:\n",
    "            continue\n",
    "        period_safe = safe_str(period)\n",
    "        suffix = f\"{model_safe}_{period_safe}\"\n",
    "        plot_true_vs_pred(df_sel, os.path.join(model_output_dir, f\"true_vs_pred_{suffix}.png\"))\n",
    "        plot_true_pred_over_time(df_sel, os.path.join(model_output_dir, f\"time_series_{suffix}.png\"))\n",
    "        plot_residual_hist(df_sel, os.path.join(model_output_dir, f\"residual_hist_{suffix}.png\"))\n",
    "        plot_residual_vs_pred(df_sel, os.path.join(model_output_dir, f\"residual_vs_pred_{suffix}.png\"))\n",
    "        print(f\"Plots for {model}, {period} saved.\")\n",
    "\n",
    "# Comparison plots (R2, RMSE, MAE)\n",
    "df_metric = pd.read_csv(METRIC_FILE)\n",
    "\n",
    "METRICS = [\n",
    "    (\"R2\", \"Train R2\", \"Test R2\"),\n",
    "    (\"RMSE\", \"Train RMSE\", \"Test RMSE\"),\n",
    "    (\"MAE\", \"Train MAE\", \"Test MAE\")\n",
    "]\n",
    "\n",
    "for model in df_metric[\"Modell\"].unique():\n",
    "    model_safe = safe_str(model)\n",
    "    model_output_dir = os.path.join(BASE_OUTPUT_DIR, model_safe)\n",
    "    os.makedirs(model_output_dir, exist_ok=True)\n",
    "\n",
    "    df_model_metric = df_metric[df_metric[\"Modell\"] == model]\n",
    "    if df_model_metric.empty:\n",
    "        continue\n",
    "\n",
    "    for metric_name, train_col, test_col in METRICS:\n",
    "        df_plot = df_model_metric.melt(\n",
    "            id_vars=[\"Bereich\", \"Modell\"],\n",
    "            value_vars=[train_col, test_col],\n",
    "            var_name=\"Dataset\",\n",
    "            value_name=metric_name\n",
    "        )\n",
    "        df_plot[\"Dataset\"] = df_plot[\"Dataset\"].apply(\n",
    "            lambda x: \"Train\" if \"Train\" in x else \"Test\"\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sns.barplot(\n",
    "            data=df_plot,\n",
    "            x=\"Bereich\",\n",
    "            y=metric_name,\n",
    "            hue=\"Dataset\",\n",
    "            ci=None,\n",
    "            palette={\"Train\": \"skyblue\", \"Test\": \"salmon\"}\n",
    "        )\n",
    "        plt.title(f\"{model}: Train and Test {metric_name}\")\n",
    "        plt.xlabel(\"Region\")\n",
    "        plt.ylabel(metric_name)\n",
    "        plt.legend(title=\"Dataset\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = os.path.join(\n",
    "            model_output_dir,\n",
    "            f\"model_comparison_{metric_name.lower()}.png\"\n",
    "        )\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "        print(f\"Model comparison for {model}, {metric_name} saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b52076-dc74-4ab5-9851-a6f7f223c51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
